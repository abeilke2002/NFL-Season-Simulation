{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2617d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nfl_data_py as nfl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold, KFold\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "# Remove the wrong one if it's already imported\n",
    "if 'functions' in sys.modules:\n",
    "    del sys.modules['functions']\n",
    "\n",
    "# Ensure correct path\n",
    "sys.path.insert(0, '/Users/aidanbeilke/Desktop/Football Projects')\n",
    "\n",
    "# Now re-import\n",
    "from functions import bayes_modeling_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daecd6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 done.\n",
      "2001 done.\n",
      "2002 done.\n",
      "2003 done.\n",
      "2004 done.\n",
      "2005 done.\n",
      "2006 done.\n",
      "2007 done.\n",
      "2008 done.\n",
      "2009 done.\n",
      "2010 done.\n",
      "2011 done.\n",
      "2012 done.\n",
      "2013 done.\n",
      "2014 done.\n",
      "2015 done.\n",
      "2016 done.\n",
      "2017 done.\n",
      "2018 done.\n",
      "2019 done.\n",
      "2020 done.\n",
      "2021 done.\n",
      "2022 done.\n",
      "2023 done.\n",
      "2024 done.\n",
      "Downcasting floats.\n"
     ]
    }
   ],
   "source": [
    "pbp = nfl.import_pbp_data(list(range(2000,2025)))\n",
    "\n",
    "pbp = pbp[pbp['season_type'] == 'REG']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13669c2",
   "metadata": {},
   "source": [
    "### Passing Yards Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d3c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp = pbp[pbp['season_type'] == 'REG']\n",
    "\n",
    "summary = (\n",
    "    pbp.groupby(['posteam', 'season'], as_index=False)\n",
    "      .agg({\n",
    "          'pass_attempt': 'sum',\n",
    "          'passing_yards': 'sum',\n",
    "          'air_epa': 'sum',\n",
    "          'complete_pass': 'sum'\n",
    "      })\n",
    ").sort_values(['posteam', 'season'])\n",
    "\n",
    "summary['completion_perc'] = summary['complete_pass'] / summary['pass_attempt']\n",
    "\n",
    "summary['passing_yards_last_year'] = summary.groupby('posteam')['passing_yards'].shift(1)\n",
    "summary['pass_attempt_last_year'] = summary.groupby('posteam')['pass_attempt'].shift(1)\n",
    "summary['completion_perc_last_year'] = summary.groupby('posteam')['completion_perc'].shift(1)\n",
    "summary['passing_yards_two_year'] = summary.groupby('posteam')['passing_yards'].shift(2)\n",
    "summary['pass_attempt_two_year'] = summary.groupby('posteam')['pass_attempt'].shift(2)\n",
    "summary['completion_perc_two_year'] = summary.groupby('posteam')['completion_perc'].shift(2)\n",
    "\n",
    "summary = summary.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "103eaaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 470.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "features = [\n",
    "    'passing_yards_last_year',\n",
    "    'pass_attempt_last_year',\n",
    "    'completion_perc_last_year',\n",
    "    'passing_yards_two_year',\n",
    "    'pass_attempt_two_year',\n",
    "    'completion_perc_two_year'\n",
    "]\n",
    "\n",
    "# Drop rows with missing values in target or features\n",
    "model_df = summary.dropna(subset=features + ['passing_yards'])\n",
    "\n",
    "X = model_df[features].values\n",
    "y = model_df['passing_yards'].values\n",
    "\n",
    "# Fit linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Predict and calculate MSE\n",
    "preds = lr.predict(X)\n",
    "mse = mean_squared_error(y, preds)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f989a779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 474.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidanbeilke/.pyenv/versions/3.10.13/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:213: LinAlgWarning: Ill-conditioned matrix (rcond=3.69583e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# --- Define features & target ---\n",
    "features = [\n",
    "    'passing_yards_last_year',\n",
    "    'pass_attempt_last_year',\n",
    "    'completion_perc_last_year',\n",
    "    'passing_yards_two_year',\n",
    "    'pass_attempt_two_year',\n",
    "    'completion_perc_two_year'\n",
    "]\n",
    "target = 'passing_yards'\n",
    "\n",
    "# --- Drop missing values ---\n",
    "data = summary.dropna(subset=features + [target])\n",
    "\n",
    "# --- Split train/test ---\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Ridge Regression ---\n",
    "ridge = Ridge(alpha=1.0)  # You can tune alpha\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# --- Predictions ---\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "# --- Evaluation ---\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ccf5eb",
   "metadata": {},
   "source": [
    "### Rushing Yards Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcf10fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 316.28\n"
     ]
    }
   ],
   "source": [
    "pbp = pbp[pbp['season_type'] == 'REG']\n",
    "\n",
    "summary = (\n",
    "    pbp.groupby(['posteam', 'season'], as_index=False)\n",
    "      .agg({\n",
    "          'rush_attempt': 'sum',\n",
    "          'rushing_yards': 'sum',\n",
    "      })\n",
    ").sort_values(['posteam', 'season'])\n",
    "\n",
    "summary['yards_per_attempt'] = summary['rushing_yards'] / summary['rush_attempt']\n",
    "\n",
    "summary['rushing_yards_last_year'] = summary.groupby('posteam')['rushing_yards'].shift(1)\n",
    "summary['rush_attempt_last_year'] = summary.groupby('posteam')['rush_attempt'].shift(1)\n",
    "summary['yards_per_attempt_last_year'] = summary.groupby('posteam')['yards_per_attempt'].shift(1)\n",
    "summary['rushing_yards_two_year'] = summary.groupby('posteam')['rushing_yards'].shift(2)\n",
    "summary['rush_attempt_two_year'] = summary.groupby('posteam')['rush_attempt'].shift(2)\n",
    "summary['yards_per_attempt_two_year'] = summary.groupby('posteam')['yards_per_attempt'].shift(2)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "features = [\n",
    "    'rushing_yards_last_year',\n",
    "    'rush_attempt_last_year',\n",
    "    'yards_per_attempt_last_year',\n",
    "    'rushing_yards_two_year',\n",
    "    'rush_attempt_two_year',\n",
    "    'yards_per_attempt_two_year'\n",
    "]\n",
    "\n",
    "# Drop rows with missing values in target or features\n",
    "model_df = summary.dropna(subset=features + ['rushing_yards'])\n",
    "\n",
    "X = model_df[features].values\n",
    "y = model_df['rushing_yards'].values\n",
    "\n",
    "# Fit linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Predict and calculate MSE\n",
    "preds = lr.predict(X)\n",
    "mse = mean_squared_error(y, preds)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed3c6d",
   "metadata": {},
   "source": [
    "### EPA Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a10b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predicted_qb_epa(pbp, holdout_season, n_splits=5):\n",
    "\n",
    "    summary = (\n",
    "        pbp.groupby(['posteam', 'season'], as_index=False)\n",
    "        .agg({\n",
    "            'fumble_forced': 'sum',\n",
    "            'air_epa': 'mean',\n",
    "            'yac_epa': 'mean',\n",
    "            'qb_scramble' : 'sum'\n",
    "        })\n",
    "    ).sort_values(['posteam', 'season'])\n",
    "\n",
    "    teams = summary['posteam'].unique()\n",
    "\n",
    "    placeholder_rows = pd.DataFrame({\n",
    "    'posteam': teams,\n",
    "    'season': 2025,\n",
    "    'qb_epa': np.nan,\n",
    "    'air_epa': np.nan,\n",
    "    'yac_epa': np.nan,\n",
    "    'qb_scramble' : np.nan\n",
    "    })\n",
    "\n",
    "    summary = pd.concat([summary, placeholder_rows], ignore_index=True).sort_values(['posteam', 'season'])\n",
    "\n",
    "    for lag in [1, 2]:\n",
    "        summary[f'qb_epa_lag{lag}'] = summary.groupby('posteam')['qb_epa'].shift(lag)\n",
    "        summary[f'air_epa_lag{lag}'] = summary.groupby('posteam')['air_epa'].shift(lag)\n",
    "        summary[f'yac_epa_lag{lag}'] = summary.groupby('posteam')['yac_epa'].shift(lag)\n",
    "        summary[f'qb_scrambles_lag{lag}'] = summary.groupby('posteam')['qb_scramble'].shift(lag)\n",
    "\n",
    "    summary = summary[~((summary['season'] <= 2024) & summary.isna().any(axis=1))]\n",
    "    summary = summary[summary['posteam'] != '']\n",
    "    summary = summary[summary['season'] >= 2002]\n",
    "\n",
    "    features = [\n",
    "        'qb_epa_lag1',\n",
    "        'air_epa_lag1',\n",
    "        'yac_epa_lag1',\n",
    "        'qb_scrambles_lag1'\n",
    "        'qb_epa_lag2',\n",
    "        'yac_epa_lag2',\n",
    "        'air_epa_lag2',\n",
    "        'qb_scrambles_lag2'\n",
    "    ]\n",
    "\n",
    "    # Separate holdout season\n",
    "    holdout_df = summary[summary['season'] == holdout_season]\n",
    "    train_df = summary[summary['season'] < holdout_season].copy().dropna()\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_all = train_df[features].values\n",
    "    X_train_all_scaled = scaler.fit_transform(X_train_all)\n",
    "\n",
    "    y_train_all = train_df['qb_epa'].values\n",
    "\n",
    "    # 1. Cross-validation predictions on train_df\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof_preds = np.zeros(len(train_df))  # out-of-fold predictions\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_train_all_scaled):\n",
    "        X_tr, X_val = X_train_all_scaled[train_idx], X_train_all_scaled[val_idx]\n",
    "        y_tr = y_train_all[train_idx]\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_tr, y_tr)\n",
    "        oof_preds[val_idx] = model.predict(X_val)\n",
    "\n",
    "    train_df['pred_qb_epa'] = oof_preds\n",
    "    train_df['team'] = train_df['posteam']\n",
    "\n",
    "    # 2. Fit on all training data, predict holdout season\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_all_scaled, y_train_all)\n",
    "\n",
    "    X_holdout = scaler.transform(holdout_df[features].values)\n",
    "    holdout_df = holdout_df.copy()\n",
    "    holdout_df['pred_qb_epa'] = model.predict(X_holdout)\n",
    "    holdout_df['team'] = holdout_df['posteam']\n",
    "\n",
    "    # 3. Combine and return\n",
    "    combined_df = pd.concat([train_df, holdout_df], ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1e75c4",
   "metadata": {},
   "source": [
    "### Offensive Interceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e68084a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predicted_offensive_interceptions(pbp, holdout_season, n_splits=5):\n",
    "\n",
    "    summary = (\n",
    "        pbp.groupby(['posteam', 'season'], as_index=False)\n",
    "        .agg({\n",
    "            'passing_yards': 'sum',\n",
    "            'pass_attempt': 'sum',\n",
    "            'interception': 'sum'\n",
    "        })\n",
    "    ).sort_values(['posteam', 'season'])\n",
    "\n",
    "    teams = summary['posteam'].unique()\n",
    "\n",
    "    placeholder_rows = pd.DataFrame({\n",
    "    'posteam': teams,\n",
    "    'season': 2025,\n",
    "    'passing_yards': np.nan,\n",
    "    'pass_attempt': np.nan,\n",
    "    'interception': np.nan\n",
    "    })\n",
    "\n",
    "    summary = pd.concat([summary, placeholder_rows], ignore_index=True).sort_values(['defteam', 'season'])\n",
    "\n",
    "    for lag in [1, 2]:\n",
    "        summary[f'passing_yards_lag{lag}'] = summary.groupby('posteam')['passing_yards'].shift(lag)\n",
    "        summary[f'pass_attempts_lag{lag}'] = summary.groupby('posteam')['pass_attempt'].shift(lag)\n",
    "        summary[f'interceptions_lag{lag}'] = summary.groupby('posteam')['interception'].shift(lag)\n",
    "\n",
    "    summary = summary[~((summary['season'] <= 2024) & summary.isna().any(axis=1))]\n",
    "    summary = summary[summary['posteam'] != '']\n",
    "    summary = summary[summary['season'] >= 2002]\n",
    "\n",
    "    features = [\n",
    "        'passing_yards_lag1',\n",
    "        'pass_attempts_lag1',\n",
    "        'interceptions_lag1',\n",
    "        'passing_yards_lag2',\n",
    "        'pass_attempts_lag2',\n",
    "        'interceptions_lag2'\n",
    "    ]\n",
    "\n",
    "    # Separate holdout season\n",
    "    holdout_df = summary[summary['season'] == holdout_season]\n",
    "    train_df = summary[summary['season'] < holdout_season].copy().dropna()\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_all = train_df[features].values\n",
    "    X_train_all_scaled = scaler.fit_transform(X_train_all)\n",
    "\n",
    "    y_train_all = train_df['interception'].values\n",
    "\n",
    "    # 1. Cross-validation predictions on train_df\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof_preds = np.zeros(len(train_df))  # out-of-fold predictions\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_train_all_scaled):\n",
    "        X_tr, X_val = X_train_all_scaled[train_idx], X_train_all_scaled[val_idx]\n",
    "        y_tr = y_train_all[train_idx]\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_tr, y_tr)\n",
    "        oof_preds[val_idx] = model.predict(X_val)\n",
    "\n",
    "    train_df['pred_interceptions'] = oof_preds\n",
    "    train_df['team'] = train_df['posteam']\n",
    "\n",
    "    # 2. Fit on all training data, predict holdout season\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_all_scaled, y_train_all)\n",
    "\n",
    "    X_holdout = scaler.transform(holdout_df[features].values)\n",
    "    holdout_df = holdout_df.copy()\n",
    "    holdout_df['pred_interceptions'] = model.predict(X_holdout)\n",
    "    holdout_df['team'] = holdout_df['posteam']\n",
    "\n",
    "    # 3. Combine and return\n",
    "    combined_df = pd.concat([train_df, holdout_df], ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e1afe",
   "metadata": {},
   "source": [
    "### Time to Throw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5f1152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngs = nfl.import_ngs_data('passing', list(range(2000, 2024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21486fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['season',\n",
       " 'season_type',\n",
       " 'week',\n",
       " 'player_display_name',\n",
       " 'player_position',\n",
       " 'team_abbr',\n",
       " 'avg_time_to_throw',\n",
       " 'avg_completed_air_yards',\n",
       " 'avg_intended_air_yards',\n",
       " 'avg_air_yards_differential',\n",
       " 'aggressiveness',\n",
       " 'max_completed_air_distance',\n",
       " 'avg_air_yards_to_sticks',\n",
       " 'attempts',\n",
       " 'pass_yards',\n",
       " 'pass_touchdowns',\n",
       " 'interceptions',\n",
       " 'passer_rating',\n",
       " 'completions',\n",
       " 'completion_percentage',\n",
       " 'expected_completion_percentage',\n",
       " 'completion_percentage_above_expectation',\n",
       " 'avg_air_distance',\n",
       " 'max_air_distance',\n",
       " 'player_gsis_id',\n",
       " 'player_first_name',\n",
       " 'player_last_name',\n",
       " 'player_jersey_number',\n",
       " 'player_short_name']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in ngs.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59542f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predicted_time_to_throw(pbp, holdout_season, n_splits=5):\n",
    "\n",
    "    pbp = nfl.import_ngs_data('passing', list(range(2000, 2024)))\n",
    "    pbp['posteam'] = pbp['team_abbr']\n",
    "\n",
    "    summary = (\n",
    "        pbp.groupby(['posteam', 'season'], as_index=False)\n",
    "        .agg({\n",
    "            'avg_time_to_throw': 'mean',\n",
    "            'attempts': 'sum',\n",
    "            'aggressiveness': 'mean'\n",
    "        })\n",
    "    ).sort_values(['posteam', 'season'])\n",
    "\n",
    "    teams = summary['posteam'].unique()\n",
    "\n",
    "    placeholder_rows = pd.DataFrame({\n",
    "    'posteam': teams,\n",
    "    'season': 2025,\n",
    "    'avg_time_to_throw': np.nan,\n",
    "    'attempts': np.nan,\n",
    "    'aggressiveness': np.nan,\n",
    "    })\n",
    "\n",
    "    summary = pd.concat([summary, placeholder_rows], ignore_index=True).sort_values(['posteam', 'season'])\n",
    "\n",
    "    for lag in [1, 2]:\n",
    "        summary[f'avg_time_to_throw_lag{lag}'] = summary.groupby('posteam')['avg_time_to_throw'].shift(lag)\n",
    "        summary[f'attempts_lag{lag}'] = summary.groupby('posteam')['attempts'].shift(lag)\n",
    "        summary[f'aggressiveness_lag{lag}'] = summary.groupby('posteam')['aggressiveness'].shift(lag)\n",
    "\n",
    "    summary = summary[~((summary['season'] <= 2024) & summary.isna().any(axis=1))]\n",
    "    summary = summary[summary['posteam'] != '']\n",
    "    summary = summary[summary['season'] >= 2002]\n",
    "\n",
    "    features = [\n",
    "        'avg_time_to_throw_lag1',\n",
    "        'attempts_lag1',\n",
    "        'aggressiveness_lag1',\n",
    "        'avg_time_to_throw_lag2',\n",
    "        'attempts_lag2',\n",
    "        'avg_time_to_throw_lag2',\n",
    "    ]\n",
    "\n",
    "    # Separate holdout season\n",
    "    holdout_df = summary[summary['season'] == holdout_season]\n",
    "    train_df = summary[summary['season'] < holdout_season].copy().dropna()\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_all = train_df[features].values\n",
    "    X_train_all_scaled = scaler.fit_transform(X_train_all)\n",
    "\n",
    "    y_train_all = train_df['avg_time_to_throw'].values\n",
    "\n",
    "    # 1. Cross-validation predictions on train_df\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof_preds = np.zeros(len(train_df))  # out-of-fold predictions\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_train_all_scaled):\n",
    "        X_tr, X_val = X_train_all_scaled[train_idx], X_train_all_scaled[val_idx]\n",
    "        y_tr = y_train_all[train_idx]\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_tr, y_tr)\n",
    "        oof_preds[val_idx] = model.predict(X_val)\n",
    "\n",
    "    train_df['pred_time_to_throw'] = oof_preds\n",
    "    train_df['team'] = train_df['posteam']\n",
    "\n",
    "    # 2. Fit on all training data, predict holdout season\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_all_scaled, y_train_all)\n",
    "\n",
    "    X_holdout = scaler.transform(holdout_df[features].values)\n",
    "    holdout_df = holdout_df.copy()\n",
    "    holdout_df['pred_time_to_throw'] = model.predict(X_holdout)\n",
    "    holdout_df['team'] = holdout_df['posteam']\n",
    "\n",
    "    # 3. Combine and return\n",
    "    combined_df = pd.concat([train_df, holdout_df], ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757cd2e0",
   "metadata": {},
   "source": [
    "### Passer Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2b1643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predicted_passer_rating(pbp, holdout_season, n_splits=5):\n",
    "\n",
    "    pbp = nfl.import_ngs_data('passing', list(range(2000, 2025)))\n",
    "    pbp['posteam'] = pbp['team_abbr']\n",
    "\n",
    "    summary = (\n",
    "        pbp.groupby(['posteam', 'season'], as_index=False)\n",
    "        .agg({\n",
    "            'passer_rating': 'mean',\n",
    "            'pass_yards': 'sum',\n",
    "            'pass_touchdowns': 'sum',\n",
    "            'interceptions' : 'sum',\n",
    "            'avg_time_to_throw' : 'mean'\n",
    "        })\n",
    "    ).sort_values(['posteam', 'season'])\n",
    "\n",
    "    summary['td_int_ratio'] = summary['pass_touchdowns'] / summary['interceptions']\n",
    "\n",
    "    teams = summary['posteam'].unique()\n",
    "\n",
    "    placeholder_rows = pd.DataFrame({\n",
    "    'posteam': teams,\n",
    "    'season': 2025,\n",
    "    'passer_rating': np.nan,\n",
    "    'pass_yards': np.nan,\n",
    "    'pass_touchdowns': np.nan,\n",
    "    'interceptions' : np.nan,\n",
    "    'avg_time_to_throw' : np.nan,\n",
    "    'td_int_ratio' : np.nan\n",
    "    })\n",
    "\n",
    "    summary = pd.concat([summary, placeholder_rows], ignore_index=True).sort_values(['posteam', 'season'])\n",
    "\n",
    "    for lag in [1, 2]:\n",
    "        summary[f'passer_rating_lag{lag}'] = summary.groupby('posteam')['passer_rating'].shift(lag)\n",
    "        summary[f'pass_yards_lag{lag}'] = summary.groupby('posteam')['pass_yards'].shift(lag)\n",
    "        summary[f'pass_touchdowns_lag{lag}'] = summary.groupby('posteam')['aggressiveness'].shift(lag)\n",
    "        summary[f'interceptions_lag{lag}'] = summary.groupby('posteam')['interceptions'].shift(lag)\n",
    "        summary[f'avg_time_to_throw_lag{lag}'] = summary.groupby('posteam')['avg_time_to_throw'].shift(lag)\n",
    "        summary[f'td_int_ratio_lag{lag}'] = summary.groupby('posteam')['td_int_ratio'].shift(lag)\n",
    "\n",
    "    summary = summary[~((summary['season'] <= 2024) & summary.isna().any(axis=1))]\n",
    "    summary = summary[summary['posteam'] != '']\n",
    "    summary = summary[summary['season'] >= 2002]\n",
    "\n",
    "    features = [\n",
    "        'passer_rating_lag1',\n",
    "        'pass_yards_lag1',\n",
    "        'pass_touchdowns_lag1',\n",
    "        'interceptions_lag1',\n",
    "        'avg_time_to_throw_lag1',\n",
    "        'td_int_ratio_lag1',\n",
    "        'passer_rating_lag2',\n",
    "        'pass_yards_lag2',\n",
    "        'pass_touchdowns_lag2',\n",
    "        'interceptions_lag2',\n",
    "        'avg_time_to_throw_lag2',\n",
    "        'td_int_ratio_lag2'\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Separate holdout season\n",
    "    holdout_df = summary[summary['season'] == holdout_season]\n",
    "    train_df = summary[summary['season'] < holdout_season].copy().dropna()\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_all = train_df[features].values\n",
    "    X_train_all_scaled = scaler.fit_transform(X_train_all)\n",
    "\n",
    "    y_train_all = train_df['passer_rating'].values\n",
    "\n",
    "    # 1. Cross-validation predictions on train_df\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof_preds = np.zeros(len(train_df))  # out-of-fold predictions\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_train_all_scaled):\n",
    "        X_tr, X_val = X_train_all_scaled[train_idx], X_train_all_scaled[val_idx]\n",
    "        y_tr = y_train_all[train_idx]\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_tr, y_tr)\n",
    "        oof_preds[val_idx] = model.predict(X_val)\n",
    "\n",
    "    train_df['pred_passer_rating'] = oof_preds\n",
    "    train_df['team'] = train_df['posteam']\n",
    "\n",
    "    # 2. Fit on all training data, predict holdout season\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_all_scaled, y_train_all)\n",
    "\n",
    "    X_holdout = scaler.transform(holdout_df[features].values)\n",
    "    holdout_df = holdout_df.copy()\n",
    "    holdout_df['pred_passer_rating'] = model.predict(X_holdout)\n",
    "    holdout_df['team'] = holdout_df['posteam']\n",
    "\n",
    "    # 3. Combine and return\n",
    "    combined_df = pd.concat([train_df, holdout_df], ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183b745",
   "metadata": {},
   "source": [
    "### Defensive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6385f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>defteam</th>\n",
       "      <th>season</th>\n",
       "      <th>fumble_forced</th>\n",
       "      <th>sack</th>\n",
       "      <th>interception</th>\n",
       "      <th>incomplete_pass</th>\n",
       "      <th>passing_yards</th>\n",
       "      <th>rushing_yards</th>\n",
       "      <th>total_yards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>PHI</td>\n",
       "      <td>2024</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>3266.0</td>\n",
       "      <td>1771.0</td>\n",
       "      <td>5037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>TEN</td>\n",
       "      <td>2024</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>3216.0</td>\n",
       "      <td>2277.0</td>\n",
       "      <td>5493.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>MIA</td>\n",
       "      <td>2024</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>3829.0</td>\n",
       "      <td>1763.0</td>\n",
       "      <td>5592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>SF</td>\n",
       "      <td>2024</td>\n",
       "      <td>12.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>3476.0</td>\n",
       "      <td>2118.0</td>\n",
       "      <td>5594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>NYJ</td>\n",
       "      <td>2024</td>\n",
       "      <td>15.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>3588.0</td>\n",
       "      <td>2059.0</td>\n",
       "      <td>5647.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>GB</td>\n",
       "      <td>2024</td>\n",
       "      <td>18.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>3959.0</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>5648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>HOU</td>\n",
       "      <td>2024</td>\n",
       "      <td>9.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>3753.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>5678.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>KC</td>\n",
       "      <td>2024</td>\n",
       "      <td>14.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3970.0</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>5701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>DEN</td>\n",
       "      <td>2024</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>4112.0</td>\n",
       "      <td>1639.0</td>\n",
       "      <td>5751.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>LAC</td>\n",
       "      <td>2024</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>3762.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>5759.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>PIT</td>\n",
       "      <td>2024</td>\n",
       "      <td>19.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>4151.0</td>\n",
       "      <td>1678.0</td>\n",
       "      <td>5829.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>WAS</td>\n",
       "      <td>2024</td>\n",
       "      <td>17.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>3492.0</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>5829.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>BAL</td>\n",
       "      <td>2024</td>\n",
       "      <td>14.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>4468.0</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>5829.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>LV</td>\n",
       "      <td>2024</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3989.0</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>5971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>NE</td>\n",
       "      <td>2024</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3749.0</td>\n",
       "      <td>2233.0</td>\n",
       "      <td>5982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>SEA</td>\n",
       "      <td>2024</td>\n",
       "      <td>14.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>3930.0</td>\n",
       "      <td>2053.0</td>\n",
       "      <td>5983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>MIN</td>\n",
       "      <td>2024</td>\n",
       "      <td>11.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>4459.0</td>\n",
       "      <td>1588.0</td>\n",
       "      <td>6047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2024</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>4004.0</td>\n",
       "      <td>2051.0</td>\n",
       "      <td>6055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BUF</td>\n",
       "      <td>2024</td>\n",
       "      <td>18.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>6063.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>DET</td>\n",
       "      <td>2024</td>\n",
       "      <td>12.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>4404.0</td>\n",
       "      <td>1672.0</td>\n",
       "      <td>6076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ARI</td>\n",
       "      <td>2024</td>\n",
       "      <td>17.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>3930.0</td>\n",
       "      <td>2149.0</td>\n",
       "      <td>6079.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>CLE</td>\n",
       "      <td>2024</td>\n",
       "      <td>13.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>3878.0</td>\n",
       "      <td>2205.0</td>\n",
       "      <td>6083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>TB</td>\n",
       "      <td>2024</td>\n",
       "      <td>16.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>4464.0</td>\n",
       "      <td>1663.0</td>\n",
       "      <td>6127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>CIN</td>\n",
       "      <td>2024</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>4016.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>6138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NYG</td>\n",
       "      <td>2024</td>\n",
       "      <td>15.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>3869.0</td>\n",
       "      <td>2316.0</td>\n",
       "      <td>6185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>CHI</td>\n",
       "      <td>2024</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>3959.0</td>\n",
       "      <td>2317.0</td>\n",
       "      <td>6276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>LA</td>\n",
       "      <td>2024</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>4101.0</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>6311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>DAL</td>\n",
       "      <td>2024</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4045.0</td>\n",
       "      <td>2331.0</td>\n",
       "      <td>6376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>IND</td>\n",
       "      <td>2024</td>\n",
       "      <td>18.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>4142.0</td>\n",
       "      <td>2241.0</td>\n",
       "      <td>6383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>NO</td>\n",
       "      <td>2024</td>\n",
       "      <td>12.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>4295.0</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>6699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>JAX</td>\n",
       "      <td>2024</td>\n",
       "      <td>6.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>4605.0</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>6859.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>CAR</td>\n",
       "      <td>2024</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>4043.0</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>7099.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    defteam  season  fumble_forced  sack  interception  incomplete_pass  \\\n",
       "647     PHI    2024           21.0  41.0          13.0            192.0   \n",
       "772     TEN    2024           12.0  32.0          11.0            148.0   \n",
       "497     MIA    2024            8.0  35.0          10.0            197.0   \n",
       "722      SF    2024           12.0  37.0          11.0            167.0   \n",
       "622     NYJ    2024           15.0  43.0           7.0            187.0   \n",
       "299      GB    2024           18.0  45.0          17.0            167.0   \n",
       "322     HOU    2024            9.0  49.0          19.0            209.0   \n",
       "397      KC    2024           14.0  39.0          13.0            181.0   \n",
       "249     DEN    2024           12.0  63.0          15.0            198.0   \n",
       "447     LAC    2024           10.0  46.0          15.0            183.0   \n",
       "672     PIT    2024           19.0  40.0          17.0            183.0   \n",
       "797     WAS    2024           17.0  43.0           7.0            182.0   \n",
       "74      BAL    2024           14.0  54.0          12.0            217.0   \n",
       "472      LV    2024            6.0  38.0          10.0            181.0   \n",
       "547      NE    2024           13.0  28.0           7.0            180.0   \n",
       "697     SEA    2024           14.0  45.0          13.0            185.0   \n",
       "522     MIN    2024           11.0  49.0          24.0            198.0   \n",
       "49      ATL    2024           12.0  31.0          12.0            162.0   \n",
       "99      BUF    2024           18.0  39.0          16.0            166.0   \n",
       "274     DET    2024           12.0  37.0          16.0            221.0   \n",
       "24      ARI    2024           17.0  41.0           9.0            160.0   \n",
       "199     CLE    2024           13.0  41.0           4.0            191.0   \n",
       "747      TB    2024           16.0  46.0           7.0            205.0   \n",
       "174     CIN    2024           13.0  36.0          15.0            186.0   \n",
       "597     NYG    2024           15.0  45.0           5.0            149.0   \n",
       "149     CHI    2024           15.0  40.0          11.0            167.0   \n",
       "422      LA    2024           10.0  38.0          13.0            175.0   \n",
       "224     DAL    2024           19.0  52.0          13.0            150.0   \n",
       "347     IND    2024           18.0  36.0          16.0            151.0   \n",
       "572      NO    2024           12.0  39.0          14.0            211.0   \n",
       "372     JAX    2024            6.0  34.0           6.0            185.0   \n",
       "124     CAR    2024            8.0  32.0           9.0            161.0   \n",
       "\n",
       "     passing_yards  rushing_yards  total_yards  \n",
       "647         3266.0         1771.0       5037.0  \n",
       "772         3216.0         2277.0       5493.0  \n",
       "497         3829.0         1763.0       5592.0  \n",
       "722         3476.0         2118.0       5594.0  \n",
       "622         3588.0         2059.0       5647.0  \n",
       "299         3959.0         1689.0       5648.0  \n",
       "322         3753.0         1925.0       5678.0  \n",
       "397         3970.0         1731.0       5701.0  \n",
       "249         4112.0         1639.0       5751.0  \n",
       "447         3762.0         1997.0       5759.0  \n",
       "672         4151.0         1678.0       5829.0  \n",
       "797         3492.0         2337.0       5829.0  \n",
       "74          4468.0         1361.0       5829.0  \n",
       "472         3989.0         1982.0       5971.0  \n",
       "547         3749.0         2233.0       5982.0  \n",
       "697         3930.0         2053.0       5983.0  \n",
       "522         4459.0         1588.0       6047.0  \n",
       "49          4004.0         2051.0       6055.0  \n",
       "99          4100.0         1963.0       6063.0  \n",
       "274         4404.0         1672.0       6076.0  \n",
       "24          3930.0         2149.0       6079.0  \n",
       "199         3878.0         2205.0       6083.0  \n",
       "747         4464.0         1663.0       6127.0  \n",
       "174         4016.0         2122.0       6138.0  \n",
       "597         3869.0         2316.0       6185.0  \n",
       "149         3959.0         2317.0       6276.0  \n",
       "422         4101.0         2210.0       6311.0  \n",
       "224         4045.0         2331.0       6376.0  \n",
       "347         4142.0         2241.0       6383.0  \n",
       "572         4295.0         2404.0       6699.0  \n",
       "372         4605.0         2254.0       6859.0  \n",
       "124         4043.0         3056.0       7099.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = (\n",
    "    pbp.groupby(['defteam', 'season'], as_index=False)\n",
    "    .agg({\n",
    "        'fumble_forced': 'sum',\n",
    "        'sack': 'sum',\n",
    "        'interception': 'sum',\n",
    "        'incomplete_pass' : 'sum',\n",
    "        'passing_yards' : 'sum',\n",
    "        'rushing_yards' : 'sum'\n",
    "    })\n",
    ").sort_values(['defteam', 'season'])\n",
    "summary['total_yards'] = summary['passing_yards'] + summary['rushing_yards']\n",
    "\n",
    "summary[summary['season'] == 2024].sort_values(by = 'total_yards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443866aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predicted_yards_allowed(pbp, holdout_season, n_splits=5):\n",
    "\n",
    "    summary = (\n",
    "        pbp.groupby(['defteam', 'season'], as_index=False)\n",
    "        .agg({\n",
    "            'fumble_forced': 'sum',\n",
    "            'sack': 'sum',\n",
    "            'interception': 'sum',\n",
    "            'incomplete_pass' : 'sum',\n",
    "            'passing_yards' : 'sum',\n",
    "            'rushing_yards' : 'sum'\n",
    "        })\n",
    "    ).sort_values(['defteam', 'season'])\n",
    "    summary['total_yards'] = summary['passing_yards'] + summary['rushing_yards']\n",
    "\n",
    "    teams = summary['defteam'].unique()\n",
    "\n",
    "    placeholder_rows = pd.DataFrame({\n",
    "    'defteam': teams,\n",
    "    'season': 2025,\n",
    "    'fumble_forced': np.nan,\n",
    "    'sack': np.nan,\n",
    "    'interception': np.nan,\n",
    "    'incomplete_pass' : np.nan,\n",
    "    'passing_yards' : np.nan,\n",
    "    'rushing_yards' : np.nan,\n",
    "    'total_yards' : np.nan\n",
    "    })\n",
    "\n",
    "    summary = pd.concat([summary, placeholder_rows], ignore_index=True).sort_values(['defteam', 'season'])\n",
    "\n",
    "    for lag in [1, 2]:\n",
    "        summary[f'forced_fumbles_lag{lag}'] = summary.groupby('defteam')['fumble_forced'].shift(lag)\n",
    "        summary[f'sacks_lag{lag}'] = summary.groupby('defteam')['sack'].shift(lag)\n",
    "        summary[f'interceptions_lag{lag}'] = summary.groupby('defteam')['interception'].shift(lag)\n",
    "        summary[f'incomplete_passes_lag{lag}'] = summary.groupby('defteam')['incomplete_pass'].shift(lag)\n",
    "        summary[f'total_yards_lag{lag}'] = summary.groupby('defteam')['total_yards'].shift(lag)\n",
    "\n",
    "    summary = summary[~((summary['season'] <= 2024) & summary.isna().any(axis=1))]\n",
    "    summary = summary[summary['defteam'] != '']\n",
    "    summary = summary[summary['season'] >= 2002]\n",
    "\n",
    "    features = [\n",
    "        'forced_fumbles_lag1',\n",
    "        'sacks_lag1',\n",
    "        'interceptions_lag1',\n",
    "        'incomplete_passes_lag1',\n",
    "        'total_yards_lag1',\n",
    "        'forced_fumbles_lag2',\n",
    "        'sacks_lag2',\n",
    "        'interceptions_lag2',\n",
    "        'incomplete_passes_lag2',\n",
    "        'total_yards_lag2'\n",
    "    ]\n",
    "\n",
    "    # Separate holdout season\n",
    "    holdout_df = summary[summary['season'] == holdout_season]\n",
    "    train_df = summary[summary['season'] < holdout_season].copy().dropna()\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_all = train_df[features].values\n",
    "    X_train_all_scaled = scaler.fit_transform(X_train_all)\n",
    "\n",
    "    y_train_all = train_df['total_yards'].values\n",
    "\n",
    "    # 1. Cross-validation predictions on train_df\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof_preds = np.zeros(len(train_df))  # out-of-fold predictions\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_train_all_scaled):\n",
    "        X_tr, X_val = X_train_all_scaled[train_idx], X_train_all_scaled[val_idx]\n",
    "        y_tr = y_train_all[train_idx]\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_tr, y_tr)\n",
    "        oof_preds[val_idx] = model.predict(X_val)\n",
    "\n",
    "    train_df['pred_total_yards'] = oof_preds\n",
    "    train_df['team'] = train_df['defteam']\n",
    "\n",
    "    # 2. Fit on all training data, predict holdout season\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_all_scaled, y_train_all)\n",
    "\n",
    "    X_holdout = scaler.transform(holdout_df[features].values)\n",
    "    holdout_df = holdout_df.copy()\n",
    "    holdout_df['pred_total_yards'] = model.predict(X_holdout)\n",
    "    holdout_df['team'] = holdout_df['defteam']\n",
    "\n",
    "    # 3. Combine and return\n",
    "    combined_df = pd.concat([train_df, holdout_df], ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c80e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predicted_interceptions(pbp, holdout_season, n_splits=5):\n",
    "\n",
    "    summary = (\n",
    "        pbp.groupby(['defteam', 'season'], as_index=False)\n",
    "        .agg({\n",
    "            'fumble_forced': 'sum',\n",
    "            'sack': 'sum',\n",
    "            'interception': 'sum',\n",
    "            'incomplete_pass' : 'sum',\n",
    "            'passing_yards' : 'sum',\n",
    "            'rushing_yards' : 'sum'\n",
    "        })\n",
    "    ).sort_values(['defteam', 'season'])\n",
    "    summary['total_yards'] = summary['passing_yards'] + summary['rushing_yards']\n",
    "\n",
    "    teams = summary['defteam'].unique()\n",
    "\n",
    "    placeholder_rows = pd.DataFrame({\n",
    "    'defteam': teams,\n",
    "    'season': 2025,\n",
    "    'fumble_forced': np.nan,\n",
    "    'sack': np.nan,\n",
    "    'interception': np.nan,\n",
    "    'incomplete_pass' : np.nan,\n",
    "    'passing_yards' : np.nan,\n",
    "    'rushing_yards' : np.nan,\n",
    "    'total_yards' : np.nan\n",
    "    })\n",
    "\n",
    "    summary = pd.concat([summary, placeholder_rows], ignore_index=True).sort_values(['defteam', 'season'])\n",
    "\n",
    "    for lag in [1, 2]:\n",
    "        summary[f'forced_fumbles_lag{lag}'] = summary.groupby('defteam')['fumble_forced'].shift(lag)\n",
    "        summary[f'sacks_lag{lag}'] = summary.groupby('defteam')['sack'].shift(lag)\n",
    "        summary[f'interceptions_lag{lag}'] = summary.groupby('defteam')['interception'].shift(lag)\n",
    "        summary[f'incomplete_passes_lag{lag}'] = summary.groupby('defteam')['incomplete_pass'].shift(lag)\n",
    "        summary[f'total_yards_lag{lag}'] = summary.groupby('defteam')['total_yards'].shift(lag)\n",
    "\n",
    "    summary = summary[~((summary['season'] <= 2024) & summary.isna().any(axis=1))]\n",
    "    summary = summary[summary['defteam'] != '']\n",
    "    summary = summary[summary['season'] >= 2002]\n",
    "\n",
    "    features = [\n",
    "        'forced_fumbles_lag1',\n",
    "        'sacks_lag1',\n",
    "        'interceptions_lag1',\n",
    "        'incomplete_passes_lag1',\n",
    "        'total_yards_lag1',\n",
    "        'forced_fumbles_lag2',\n",
    "        'sacks_lag2',\n",
    "        'interceptions_lag2',\n",
    "        'incomplete_passes_lag2',\n",
    "        'total_yards_lag2'\n",
    "    ]\n",
    "\n",
    "    # Separate holdout season\n",
    "    holdout_df = summary[summary['season'] == holdout_season]\n",
    "    train_df = summary[summary['season'] < holdout_season].copy().dropna()\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_all = train_df[features].values\n",
    "    X_train_all_scaled = scaler.fit_transform(X_train_all)\n",
    "\n",
    "    y_train_all = train_df['interception'].values\n",
    "\n",
    "    # 1. Cross-validation predictions on train_df\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof_preds = np.zeros(len(train_df))  # out-of-fold predictions\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_train_all_scaled):\n",
    "        X_tr, X_val = X_train_all_scaled[train_idx], X_train_all_scaled[val_idx]\n",
    "        y_tr = y_train_all[train_idx]\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_tr, y_tr)\n",
    "        oof_preds[val_idx] = model.predict(X_val)\n",
    "\n",
    "    train_df['pred_interceptions'] = oof_preds\n",
    "    train_df['team'] = train_df['defteam']\n",
    "\n",
    "    # 2. Fit on all training data, predict holdout season\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_all_scaled, y_train_all)\n",
    "\n",
    "    X_holdout = scaler.transform(holdout_df[features].values)\n",
    "    holdout_df = holdout_df.copy()\n",
    "    holdout_df['pred_interceptions'] = model.predict(X_holdout)\n",
    "    holdout_df['team'] = holdout_df['defteam']\n",
    "\n",
    "    # 3. Combine and return\n",
    "    combined_df = pd.concat([train_df, holdout_df], ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predicted_sacks(pbp, holdout_season, n_splits=5):\n",
    "\n",
    "    summary = (\n",
    "        pbp.groupby(['defteam', 'season'], as_index=False)\n",
    "        .agg({\n",
    "            'fumble_forced': 'sum',\n",
    "            'sack': 'sum',\n",
    "            'interception': 'sum',\n",
    "            'incomplete_pass' : 'sum',\n",
    "            'passing_yards' : 'sum',\n",
    "            'rushing_yards' : 'sum'\n",
    "        })\n",
    "    ).sort_values(['defteam', 'season'])\n",
    "    summary['total_yards'] = summary['passing_yards'] + summary['rushing_yards']\n",
    "\n",
    "    teams = summary['defteam'].unique()\n",
    "\n",
    "    placeholder_rows = pd.DataFrame({\n",
    "    'defteam': teams,\n",
    "    'season': 2025,\n",
    "    'fumble_forced': np.nan,\n",
    "    'sack': np.nan,\n",
    "    'interception': np.nan,\n",
    "    'incomplete_pass' : np.nan,\n",
    "    'passing_yards' : np.nan,\n",
    "    'rushing_yards' : np.nan,\n",
    "    'total_yards' : np.nan\n",
    "    })\n",
    "\n",
    "    summary = pd.concat([summary, placeholder_rows], ignore_index=True).sort_values(['defteam', 'season'])\n",
    "\n",
    "    for lag in [1, 2]:\n",
    "        summary[f'forced_fumbles_lag{lag}'] = summary.groupby('defteam')['fumble_forced'].shift(lag)\n",
    "        summary[f'sacks_lag{lag}'] = summary.groupby('defteam')['sack'].shift(lag)\n",
    "        summary[f'interceptions_lag{lag}'] = summary.groupby('defteam')['interception'].shift(lag)\n",
    "        summary[f'incomplete_passes_lag{lag}'] = summary.groupby('defteam')['incomplete_pass'].shift(lag)\n",
    "        summary[f'total_yards_lag{lag}'] = summary.groupby('defteam')['total_yards'].shift(lag)\n",
    "\n",
    "    summary = summary[~((summary['season'] <= 2024) & summary.isna().any(axis=1))]\n",
    "    summary = summary[summary['defteam'] != '']\n",
    "    summary = summary[summary['season'] >= 2002]\n",
    "\n",
    "    features = [\n",
    "        'forced_fumbles_lag1',\n",
    "        'sacks_lag1',\n",
    "        'interceptions_lag1',\n",
    "        'incomplete_passes_lag1',\n",
    "        'total_yards_lag1',\n",
    "        'forced_fumbles_lag2',\n",
    "        'sacks_lag2',\n",
    "        'interceptions_lag2',\n",
    "        'incomplete_passes_lag2',\n",
    "        'total_yards_lag2'\n",
    "    ]\n",
    "\n",
    "    # Separate holdout season\n",
    "    holdout_df = summary[summary['season'] == holdout_season]\n",
    "    train_df = summary[summary['season'] < holdout_season].copy().dropna()\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_all = train_df[features].values\n",
    "    X_train_all_scaled = scaler.fit_transform(X_train_all)\n",
    "\n",
    "    y_train_all = train_df['sack'].values\n",
    "\n",
    "    # 1. Cross-validation predictions on train_df\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof_preds = np.zeros(len(train_df))  # out-of-fold predictions\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_train_all_scaled):\n",
    "        X_tr, X_val = X_train_all_scaled[train_idx], X_train_all_scaled[val_idx]\n",
    "        y_tr = y_train_all[train_idx]\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_tr, y_tr)\n",
    "        oof_preds[val_idx] = model.predict(X_val)\n",
    "\n",
    "    train_df['pred_total_sacks'] = oof_preds\n",
    "    train_df['team'] = train_df['defteam']\n",
    "\n",
    "    # 2. Fit on all training data, predict holdout season\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_all_scaled, y_train_all)\n",
    "\n",
    "    X_holdout = scaler.transform(holdout_df[features].values)\n",
    "    holdout_df = holdout_df.copy()\n",
    "    holdout_df['pred_total_sacks'] = model.predict(X_holdout)\n",
    "    holdout_df['team'] = holdout_df['defteam']\n",
    "\n",
    "    # 3. Combine and return\n",
    "    combined_df = pd.concat([train_df, holdout_df], ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
